{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e578ca66-1cde-4a8f-a681-95976be5edd9",
   "metadata": {},
   "source": [
    "# Exercices Chapitre 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab35c935-90ec-40c0-ab82-59bfe2453bb1",
   "metadata": {},
   "source": [
    "### 1) Lorem Ipsum is just a random txt that devs use as a placeholder for multiple things (especially web developping) when you don't have the real text and just want to test your functionnality. Put a [Lorem Ipsum](https://www.lipsum.com/) of 3 paragraphs in a txt file using python, each paragraph delimited by two new line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a4f677-0e93-49f6-8725-0956d9534dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting loremipsum\n",
      "  Downloading loremipsum-1.0.5.zip (14 kB)\n",
      "Building wheels for collected packages: loremipsum\n",
      "  Building wheel for loremipsum (setup.py): started\n",
      "  Building wheel for loremipsum (setup.py): finished with status 'done'\n",
      "  Created wheel for loremipsum: filename=loremipsum-1.0.5-py3-none-any.whl size=11674 sha256=e70ab6367e580c882d012636ba193f619dc2d93150fc18cd950369766668c305\n",
      "  Stored in directory: c:\\users\\busch\\appdata\\local\\pip\\cache\\wheels\\fb\\2b\\99\\9b59810cdd993ae3becd1737fc09a9ad052a50383925d56e7d\n",
      "Successfully built loremipsum\n",
      "Installing collected packages: loremipsum\n",
      "Successfully installed loremipsum-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install loremipsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "202f3903-90ad-48d7-899a-8e03b9b53604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loremipsum import get_paragraphs\n",
    "\n",
    "paragraphs = get_paragraphs(3)\n",
    "\n",
    "# Ouvrir un fichier en mode écriture\n",
    "with open(\"texte.txt\", \"w\") as file:\n",
    "    # Écrire les paragraphes dans le fichier\n",
    "    for paragraph in paragraphs:\n",
    "        file.write(paragraph + \"\\n\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d60d3-f039-4af6-bf9c-8c077f081cd8",
   "metadata": {},
   "source": [
    "### 2) Update the txt file by removing the first paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5767e09e-8404-4234-9bd7-05f5dd2a0be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"texte.txt\", \"r+\") as file:\n",
    "    position = file.read().find(\"\\n\")\n",
    "    if position != -1:\n",
    "        file.seek(position - 1)\n",
    "        file.truncate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48400c64-7fd3-485f-a099-bb41cc7800c3",
   "metadata": {},
   "source": [
    "### 3) Create a dict from the paper of lecun et al. and goodfellow et al. with authors, title, affiliations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "998050aa-64ad-4c97-89a9-61d315fd8ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Deep learning',\n",
       "  'authors': ['Yann LeCun', 'Yoshua Bengio', 'Geoffrey Hinton'],\n",
       "  'affiliation': ['New York University',\n",
       "   'Université de Montréal',\n",
       "   'University of Toronto']},\n",
       " {'title': 'Deep learning',\n",
       "  'authors': ['Ian Goodfellow', 'Yoshua Bengio', 'Aaron Courville'],\n",
       "  'affiliation': ['OpenAI',\n",
       "   'Université de Montréal',\n",
       "   'University of Toronto']}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = [{'title': 'Deep learning',\n",
    "        'authors': [\"Yann LeCun\", \"Yoshua Bengio\", \"Geoffrey Hinton\"],\n",
    "        'affiliation': [\"New York University\", \"Université de Montréal\", \"University of Toronto\"]\n",
    "        },\n",
    "       {'title': 'Deep learning',\n",
    "        'authors': [\"Ian Goodfellow\", \"Yoshua Bengio\", \"Aaron Courville\"],\n",
    "        'affiliation': [\"OpenAI\", \"Université de Montréal\", \"University of Toronto\"]\n",
    "        }]\n",
    "\n",
    "dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a3dab-ed01-42b2-8941-548aa4510ba9",
   "metadata": {},
   "source": [
    "### 4) Save the previously created dict in the JSON format and load it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5cefd3a1-1af1-46c3-a0ad-ef28133615d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"C:/Users/Ju/OneDrive/Documents/FSEG/M1/NoSQL/dic.json\", 'w') as fj:\n",
    "    json.dump(dic, fj)\n",
    "    \n",
    "with open(\"C:/Users/Ju/OneDrive/Documents/FSEG/M1/NoSQL/dic.json\", 'r') as fj:\n",
    "    json.load(fj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a131b-f060-4eeb-b990-66a013f4d101",
   "metadata": {},
   "source": [
    "### 5) Save the previously created dict in the pickle format. Try to open manually (i.e with a text editor), is it human readable ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d68b82fb-7de7-4fc0-8565-734361787b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pas lisible\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"dic.pickle\", 'wb') as fj:\n",
    "    pickle.dump(dic, fj)\n",
    "print(\"Pas lisible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f29caee-2dae-4ad9-860e-df5750783025",
   "metadata": {},
   "source": [
    "### 6) Parse the xml_file2 in the same way as in the lecture. put infos in a dict and save it in a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd727464-6f0a-473c-b64b-c121072e995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree\n",
    "import json\n",
    "\n",
    "xml_file = \"C:/Users/Ju/OneDrive/Documents/FSEG/M1/NoSQL/xml_file2.nxml\"\n",
    "root = lxml.etree.parse(xml_file)\n",
    "\n",
    "dic_xml={\"date\" : root.xpath(\"//date//text()\")[0], \n",
    "     \"hour\" : root.xpath(\"//hour//text()\")[0], \n",
    "     \"to\" : root.xpath(\"//to//text()\")[0],\n",
    "     \"from\" : root.xpath(\"//from//text()\")[0],\n",
    "     \"body\" : root.xpath(\"//body//text()\")[0]}\n",
    "\n",
    "with open(\"C:/Users/Ju/OneDrive/Documents/FSEG/M1/NoSQL/dic_xml.json\", 'w') as fj:\n",
    "    json.dump(dic_xml, fj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c34b2f8-d751-4b9a-8f44-398659ac78f1",
   "metadata": {},
   "source": [
    "### 7) Download an image of your choice and save it in either jpg or png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d4b7eff5-88f3-482d-bd03-83b4b1693d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "im = Image.open(requests.get(\"https://ecogestion.unistra.fr/websites/ecogestion/_Logos_/fac_-_unistra/Faculte_Gestion_Etendu.png\", \n",
    "                             stream=True).raw)\n",
    "im.save(\"image_fseg.png\", \"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ae204-878d-49c7-b43a-2bb4be1d9815",
   "metadata": {},
   "source": [
    "### 8) From the data/Chap2/data_world.json file, create a set of publisher type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62bfa35c-7ddb-482f-85eb-e0dbb688e37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DOC/NOAA/NESDIS/NCEI > National Centers for Environmental Information, NESDIS, NOAA, U.S. Department of Commerce',\n",
       " 'Alaska Fisheries Science Center',\n",
       " '',\n",
       " 'Southeast Regional Office',\n",
       " 'US National Oceanographic Data Center',\n",
       " 'Cherokee Nation Technology Solutions, U.S. Geological Survey, St. Petersburg Coastal and Marine Science Center, St. Petersburg, FL',\n",
       " 'DOC/NOAA/NOS/OCS/HSD > United States Department of Commerce (DOC), National Oceanic and Atmospheric Administration (NOAA), National Ocean Service (NOS), Office of Coast Survey (OCS), Hydrographic Surveys Division (HSD)',\n",
       " 'DRI > Desert Research Institute; DOC/NOAA/NESDIS/NCDC > National Climatic Data Center, NESDIS, NOAA, U.S. Department of Commerce',\n",
       " 'NEFSC (Principal Investigator)',\n",
       " 'DOC/NOAA/NMFS/AFSC > Alaska Fisheries Science Center (Principal Investigator)',\n",
       " 'DOC/NOAA/NMFS/NEFSC> Northeast Fisheries Science Center (Principal Investigator)',\n",
       " 'NWFSC (Principal Investigator)',\n",
       " 'NOAA-NEFSC (Principal Investigator)',\n",
       " 'DOC/NOAA/NESDIS/NCEI > National Centers for Environmental Information, NESDIS, NOAA, U.S. Department of Commerce; DOC/NOAA/NESDIS/NCDC > National Climatic Data Center, NESDIS, NOAA, U.S. Department of Commerce',\n",
       " 'Pacific Islands Fisheries Science Center',\n",
       " 'PIFSC (Principal Investigator)',\n",
       " 'DOC/NOAA/NOS/OCS/HSD > United States Department                                    of Commerce (DOC), National Oceanic and Atmospheric                                    Administration (NOAA), National Ocean Service (NOS), Office of                                    Coast Survey (OCS), Hydrographic Surveys Division                                    (HSD)',\n",
       " 'NOAA National Environmental Satelllite, Data, and Information Services (NESDIS)',\n",
       " 'DOC/NOAA/NESDIS/NCDC > National Climatic Data Center, NESDIS, NOAA, U.S. Department of Commerce',\n",
       " 'DOC/NOAA/NESDIS/NGDC > National Geophysical Data Center, NESDIS, NOAA, U.S. Department of Commerce',\n",
       " ' (Principal Investigator)',\n",
       " 'DOC/NOAA/NESDIS/NCEI > National Centers for Environmental Information, NESDIS, NOAA, U.S. Department of Commerce; LMA/UFRJ > Applied Meteorology Laboratory/Federal University of Rio de Janeiro',\n",
       " 'DOC/NOAA/NESDIS/NCEI > National Centers for Environmental Information, NESDIS, NOAA, U.S. Department of Commerce; OSDPD > NOAA Office of Satellite Data Processing and Distribution',\n",
       " 'Hawaii Institue of Marine Biology',\n",
       " 'NOAA-National Marine Fisheries Service',\n",
       " 'National Oceanic and Atmospheric Administration (NOAA), National Ocean Service (NOS), National Centers for Coastal Ocean Science (NCCOS), Center for Coastal Monitoring and Assessment (CCMA), Remote Sensing Team',\n",
       " 'Florida International University',\n",
       " 'R. G. Ford Consulting Company',\n",
       " 'R.G. FordConsulting Co.',\n",
       " 'National Oceanic and Atmospheric Administration (NOAA), National Ocean Service (NOS), National Centers for Coastal Ocean Science (NCCOS), Center for Coastal Monitoring and Assessment (CCMA), Biogeography Branch',\n",
       " 'National Oceanic and Atmospheric Administration (NOAA), National Ocean Service (NOS), National Centers for Coastal Ocean Science (NCCOS), Center for Coastal Monitoring and Assessment(CCMA)',\n",
       " 'DOC/NOAA/NESDIS/NCEI/CCOG > Center for Coasts, Oceans, and Geophysics (Custodian)',\n",
       " 'Department of Commerce (DOC), National Oceanic and Atmospheric Administration (NOAA), Ocean and Coastal Resource Management (OCRM), National Marine Protected Areas Center (MPAC)',\n",
       " 'Department of Commerce (DOC), National Oceanic and Atmospheric Administration (NOAA), Office of Ocean and Coastal Resource Management (OCRM), National Marine Protected Areas Center (MPAC)',\n",
       " 'National Oceanic and Atmospheric Administration (NOAA), National Ocean Service (NOS), Center for Operational Oceanographic Products and Services (CO-OPS)',\n",
       " 'The Unified Access Framework (UAF) (Custodian); NASA Goddard Space Flight Center, Ocean Ecology Laboratory, Ocean Biology Processing Group',\n",
       " 'Department of Commerce (DOC), National Oceanic and Atmospheric Administration (NOAA), National Ocean Service (NOS), National Centers for Coastal Ocean Science (NCCOS), Center for Coastal Monitoring and Assessment (CCMA), Biogeography Branch',\n",
       " 'NOAA Office for Coastal Management']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('C:/Users/Ju/OneDrive/Documents/FSEG/M1/NoSQL/data_world.json', 'r', encoding= \"utf-8\") as fp:\n",
    "    docs = json.load(fp)\n",
    "\n",
    "pub = []\n",
    "for i in range(len(docs)) :  \n",
    "    pub.append(docs[i].get(\"publisher\"))\n",
    "\n",
    "publisher = []\n",
    "for element in pub:\n",
    "    containt = element.get(\"name\").replace('\\n', \"\").replace('Point of Contact', \"\").replace(\" ()\", \"\")\n",
    "    if containt not in publisher:\n",
    "        publisher.append(containt)\n",
    "publisher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d3d019-e351-4f32-affa-de1d89bcf39b",
   "metadata": {},
   "source": [
    "### 9) From the data/Chap2/data_world.json file, delete the key of your choice and save the new dict as data_world_cleaned.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8b977c4-77fc-4205-a2e9-79ea2841a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('C:/Users/Ju/OneDrive/Documents/FSEG/M1/NoSQL/data_world.json', 'r') as file:\n",
    "\tdata = json.load(file)\n",
    "\n",
    "key_to_remove = \"identifier\"\n",
    "for i in range(len(data)):\n",
    "    data[i].pop(key_to_remove)\n",
    "    \n",
    "with open('C:/Users/Ju/OneDrive/Documents/FSEG/M1/NoSQL/data_world_cleaned.json', 'w') as file:\n",
    "\tjson.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340e30d-3654-4699-a654-9cdcc4a616f9",
   "metadata": {},
   "source": [
    "### 10) From the data/Chap2/data_world.json file, create the co-occurence matrix between \"accessLevel\" and \"accrualPeriodicity\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1757ac-22de-4dfa-ac97-07a37080edef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
